{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\DELL\\\\Documents\\\\Data Science\\\\Projects\\\\Chicken_Disease_Classification\\\\research'"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"../\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'c:\\\\Users\\\\DELL\\\\Documents\\\\Data Science\\\\Projects\\\\Chicken_Disease_Classification'"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataclasses import dataclass\n",
    "from pathlib import Path\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class TrainingConfig:\n",
    "    root_dir: Path\n",
    "    trained_model_path: Path\n",
    "    updated_base_model_path: Path\n",
    "    training_data: Path\n",
    "    params_epochs: int\n",
    "    params_batch_size: int\n",
    "    params_is_augmentation: bool\n",
    "    params_image_size: list\n",
    "\n",
    "\n",
    "\n",
    "@dataclass(frozen=True)\n",
    "class PrepareCallbacksConfig:\n",
    "    root_dir: Path\n",
    "    tensorboard_root_log_dir: Path\n",
    "    checkpoint_model_filepath: Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-03 21:23:54,389: WARNING: module_wrapper: From c:\\Users\\DELL\\.conda\\envs\\chicken\\lib\\site-packages\\keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "]\n"
     ]
    }
   ],
   "source": [
    "from cnnClassifier.constants import *\n",
    "from cnnClassifier.utils.common import read_yaml, create_directories\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConfigurationManager:\n",
    "    def __init__(\n",
    "        self, \n",
    "        config_filepath = CONFIG_FILE_PATH,\n",
    "        params_filepath = PARAMS_FILE_PATH):\n",
    "        self.config = read_yaml(config_filepath)\n",
    "        self.params = read_yaml(params_filepath)\n",
    "        create_directories([self.config.artifacts_root])\n",
    "\n",
    "\n",
    "    \n",
    "    def get_prepare_callback_config(self) -> PrepareCallbacksConfig:\n",
    "        config = self.config.prepare_callbacks\n",
    "        model_ckpt_dir = os.path.dirname(config.checkpoint_model_filepath)\n",
    "        create_directories([\n",
    "            Path(model_ckpt_dir),\n",
    "            Path(config.tensorboard_root_log_dir)\n",
    "        ])\n",
    "\n",
    "        prepare_callback_config = PrepareCallbacksConfig(\n",
    "            root_dir=Path(config.root_dir),\n",
    "            tensorboard_root_log_dir=Path(config.tensorboard_root_log_dir),\n",
    "            checkpoint_model_filepath=Path(config.checkpoint_model_filepath)\n",
    "        )\n",
    "\n",
    "        return prepare_callback_config\n",
    "    \n",
    "\n",
    "    \n",
    "    def get_training_config(self) -> TrainingConfig:\n",
    "        training = self.config.training\n",
    "        prepare_base_model = self.config.prepare_base_model\n",
    "        params = self.params\n",
    "        training_data = os.path.join(self.config.data_ingestion.train_data_dir)\n",
    "        create_directories([\n",
    "            Path(training.root_dir)\n",
    "        ])\n",
    "\n",
    "        training_config = TrainingConfig(\n",
    "            root_dir=Path(training.root_dir),\n",
    "            trained_model_path=Path(training.trained_model_path),\n",
    "            updated_base_model_path=Path(prepare_base_model.updated_base_model_path),\n",
    "            training_data=Path(training_data),\n",
    "            params_epochs=params.EPOCHS,\n",
    "            params_batch_size=params.BATCH_SIZE,\n",
    "            params_is_augmentation=params.AUGMENTATION,\n",
    "            params_image_size=params.IMAGE_SIZE\n",
    "        )\n",
    "\n",
    "        return training_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "class PrepareCallback:\n",
    "    def __init__(self, config: PrepareCallbacksConfig):\n",
    "        self.config = config\n",
    "\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def _create_tb_callbacks(self):\n",
    "        timestamp = time.strftime(\"%Y-%m-%d-%H-%M-%S\")\n",
    "        tb_running_log_dir = os.path.join(\n",
    "            self.config.tensorboard_root_log_dir,\n",
    "            f\"tb_logs_at_{timestamp}\",\n",
    "        )\n",
    "        return tf.keras.callbacks.TensorBoard(log_dir=tb_running_log_dir)\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def _create_ckpt_callbacks(self):\n",
    "        return tf.keras.callbacks.ModelCheckpoint(\n",
    "            filepath=str(self.config.checkpoint_model_filepath),\n",
    "            save_best_only=True\n",
    "        )\n",
    "\n",
    "\n",
    "    def get_tb_ckpt_callbacks(self):\n",
    "        return [\n",
    "            self._create_tb_callbacks,\n",
    "            self._create_ckpt_callbacks\n",
    "        ]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import urllib.request as request\n",
    "from zipfile import ZipFile\n",
    "import tensorflow as tf\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Training:\n",
    "    def __init__(self, config: TrainingConfig):\n",
    "        self.config = config\n",
    "    \n",
    "    def get_base_model(self):\n",
    "        self.model = tf.keras.models.load_model(\n",
    "            self.config.updated_base_model_path\n",
    "        )\n",
    "    \n",
    "    def train_valid_generator(self):\n",
    "\n",
    "        datagenerator_kwargs = dict(\n",
    "            rescale = 1./255,\n",
    "            validation_split=0.20\n",
    "        )\n",
    "\n",
    "        dataflow_kwargs = dict(\n",
    "            target_size=self.config.params_image_size[:-1],\n",
    "            batch_size=self.config.params_batch_size,\n",
    "            interpolation=\"bilinear\"\n",
    "        )\n",
    "\n",
    "        valid_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "            **datagenerator_kwargs\n",
    "        )\n",
    "\n",
    "        self.valid_generator = valid_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"validation\",\n",
    "            shuffle=False, # Whether the images in the validation set should be shuffled before each epoch\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "        \n",
    "        # flow_from_directory returns:\n",
    "        # A DirectoryIterator yielding tuples of (x, y) where x is a numpy array containing\n",
    "        # a batch of images with shape (batch_size, *target_size, channels) and y is a numpy \n",
    "        # array of corresponding labels.\n",
    "\n",
    "        if self.config.params_is_augmentation:\n",
    "            train_datagenerator = tf.keras.preprocessing.image.ImageDataGenerator(\n",
    "                rotation_range=60,\n",
    "                horizontal_flip=True,\n",
    "                width_shift_range=0.3,\n",
    "                height_shift_range=0.3,\n",
    "                shear_range=0.2,\n",
    "                zoom_range=0.4,\n",
    "                **datagenerator_kwargs\n",
    "            )\n",
    "        else:\n",
    "            train_datagenerator = valid_datagenerator\n",
    "\n",
    "        self.train_generator = train_datagenerator.flow_from_directory(\n",
    "            directory=self.config.training_data,\n",
    "            subset=\"training\",\n",
    "            shuffle=True,\n",
    "            **dataflow_kwargs\n",
    "        )\n",
    "\n",
    "    @staticmethod\n",
    "    def save_model(path: Path, model: tf.keras.Model):\n",
    "        model.save(path)\n",
    "\n",
    "\n",
    "    def train(self, callback_list: list):\n",
    "        self.steps_per_epoch = self.train_generator.samples // self.train_generator.batch_size\n",
    "        self.validation_steps = self.valid_generator.samples // self.valid_generator.batch_size\n",
    "\n",
    "        self.model.fit(\n",
    "            self.train_generator,\n",
    "            epochs=self.config.params_epochs,\n",
    "            steps_per_epoch=self.steps_per_epoch,\n",
    "            validation_steps=self.validation_steps,\n",
    "            validation_data=self.valid_generator,\n",
    "            callbacks=callback_list\n",
    "        )\n",
    "\n",
    "        self.save_model(\n",
    "            path=self.config.trained_model_path,\n",
    "            model=self.model\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the above code snippet, it looks like the data is split into training and validation sets using the subset parameter of the flow_from_directory method. The shuffle parameter is then used to control whether the images within each subset (training or validation) are shuffled before each epoch during training.\n",
    "\n",
    "Let me clarify how the split and shuffling happen in this code:\n",
    "\n",
    "Data Splitting:\n",
    "\n",
    "subset=\"training\": This creates a generator (self.train_generator) for the training subset of images. The training subset typically includes the portion of the data not used for validation. The specific images included in the training set are determined by the order in which they are found in the specified directory (self.config.training_data).\n",
    "\n",
    "subset=\"validation\": This creates a generator (self.valid_generator) for the validation subset of images. The validation subset includes the portion of the data specified by the validation_split parameter (20% in your case). The specific images included in the validation set are also determined by the order in which they are found in the specified directory.\n",
    "\n",
    "Shuffling:\n",
    "\n",
    "shuffle=True for the training set (self.train_generator): This means that the order of images in the training set will be randomized before each epoch during training. This is beneficial for preventing the model from memorizing the order of the training data and helps in achieving better generalization.\n",
    "\n",
    "shuffle=False for the validation set (self.valid_generator): This means that the order of images in the validation set will remain constant across epochs. This is often done during validation to ensure consistent evaluation results and facilitate comparisons between different models or training runs.\n",
    "\n",
    "In summary, the data splitting is done using the subset parameter, and shuffling is controlled by the shuffle parameter. The training set is shuffled before each epoch, while the validation set remains constant in order across epochs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-03 21:24:08,496: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2023-12-03 21:24:08,502: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-12-03 21:24:08,504: INFO: common: created directory at: artifacts]\n",
      "[2023-12-03 21:24:08,508: INFO: common: created directory at: artifacts\\prepare_callbacks\\checkpoint_dir]\n",
      "[2023-12-03 21:24:08,510: INFO: common: created directory at: artifacts\\prepare_callbacks\\tensorboard_log_dir]\n",
      "[2023-12-03 21:24:08,521: INFO: common: created directory at: artifacts\\training]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-03 21:24:09,051: WARNING: module_wrapper: From c:\\Users\\DELL\\.conda\\envs\\chicken\\lib\\site-packages\\keras\\src\\backend.py:1398: The name tf.executing_eagerly_outside_functions is deprecated. Please use tf.compat.v1.executing_eagerly_outside_functions instead.\n",
      "]\n",
      "[2023-12-03 21:24:09,277: WARNING: module_wrapper: From c:\\Users\\DELL\\.conda\\envs\\chicken\\lib\\site-packages\\keras\\src\\layers\\pooling\\max_pooling2d.py:161: The name tf.nn.max_pool is deprecated. Please use tf.nn.max_pool2d instead.\n",
      "]\n",
      "Found 96 images belonging to 2 classes.\n",
      "Found 384 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "[2023-12-03 21:24:13,395: WARNING: module_wrapper: From c:\\Users\\DELL\\.conda\\envs\\chicken\\lib\\site-packages\\keras\\src\\utils\\tf_utils.py:492: The name tf.ragged.RaggedTensorValue is deprecated. Please use tf.compat.v1.ragged.RaggedTensorValue instead.\n",
      "]\n",
      "24/24 [==============================] - 150s 6s/step - loss: 10.0983 - accuracy: 0.6068 - precision_1: 0.6068 - recall_1: 0.6068 - auc_2: 0.6049 - val_loss: 4.7815 - val_accuracy: 0.5000 - val_precision_1: 0.5000 - val_recall_1: 0.5000 - val_auc_2: 0.5573\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\.conda\\envs\\chicken\\lib\\site-packages\\keras\\src\\engine\\training.py:3103: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 2/15\n",
      "24/24 [==============================] - 139s 6s/step - loss: 9.9320 - accuracy: 0.5729 - precision_1: 0.5729 - recall_1: 0.5729 - auc_2: 0.5844 - val_loss: 1.8642 - val_accuracy: 0.7500 - val_precision_1: 0.7500 - val_recall_1: 0.7500 - val_auc_2: 0.7935\n",
      "Epoch 3/15\n",
      "24/24 [==============================] - 145s 6s/step - loss: 4.7750 - accuracy: 0.7109 - precision_1: 0.7109 - recall_1: 0.7109 - auc_2: 0.7179 - val_loss: 0.8964 - val_accuracy: 0.8854 - val_precision_1: 0.8854 - val_recall_1: 0.8854 - val_auc_2: 0.9414\n",
      "Epoch 4/15\n",
      "24/24 [==============================] - 161s 7s/step - loss: 5.1568 - accuracy: 0.6745 - precision_1: 0.6745 - recall_1: 0.6745 - auc_2: 0.6888 - val_loss: 0.9294 - val_accuracy: 0.8542 - val_precision_1: 0.8542 - val_recall_1: 0.8542 - val_auc_2: 0.9019\n",
      "Epoch 5/15\n",
      "24/24 [==============================] - 144s 6s/step - loss: 1.9108 - accuracy: 0.8229 - precision_1: 0.8229 - recall_1: 0.8229 - auc_2: 0.8651 - val_loss: 0.5665 - val_accuracy: 0.9479 - val_precision_1: 0.9479 - val_recall_1: 0.9479 - val_auc_2: 0.9664\n",
      "Epoch 6/15\n",
      "24/24 [==============================] - 147s 6s/step - loss: 1.5946 - accuracy: 0.8464 - precision_1: 0.8464 - recall_1: 0.8464 - auc_2: 0.8788 - val_loss: 1.8172 - val_accuracy: 0.7917 - val_precision_1: 0.7917 - val_recall_1: 0.7917 - val_auc_2: 0.8605\n",
      "Epoch 7/15\n",
      "24/24 [==============================] - 140s 6s/step - loss: 4.6654 - accuracy: 0.7109 - precision_1: 0.7109 - recall_1: 0.7109 - auc_2: 0.7460 - val_loss: 0.3638 - val_accuracy: 0.9583 - val_precision_1: 0.9583 - val_recall_1: 0.9583 - val_auc_2: 0.9768\n",
      "Epoch 8/15\n",
      "24/24 [==============================] - 133s 5s/step - loss: 1.6318 - accuracy: 0.8516 - precision_1: 0.8516 - recall_1: 0.8516 - auc_2: 0.8772 - val_loss: 0.8555 - val_accuracy: 0.8542 - val_precision_1: 0.8542 - val_recall_1: 0.8542 - val_auc_2: 0.9207\n",
      "Epoch 9/15\n",
      "24/24 [==============================] - 143s 6s/step - loss: 1.7689 - accuracy: 0.8333 - precision_1: 0.8333 - recall_1: 0.8333 - auc_2: 0.8840 - val_loss: 1.5400 - val_accuracy: 0.8646 - val_precision_1: 0.8646 - val_recall_1: 0.8646 - val_auc_2: 0.8990\n",
      "Epoch 10/15\n",
      "24/24 [==============================] - 134s 6s/step - loss: 0.9126 - accuracy: 0.8880 - precision_1: 0.8880 - recall_1: 0.8880 - auc_2: 0.9282 - val_loss: 2.5758 - val_accuracy: 0.7917 - val_precision_1: 0.7917 - val_recall_1: 0.7917 - val_auc_2: 0.8235\n",
      "Epoch 11/15\n",
      "24/24 [==============================] - 135s 6s/step - loss: 3.6068 - accuracy: 0.7057 - precision_1: 0.7057 - recall_1: 0.7057 - auc_2: 0.7504 - val_loss: 0.3479 - val_accuracy: 0.9479 - val_precision_1: 0.9479 - val_recall_1: 0.9479 - val_auc_2: 0.9654\n",
      "Epoch 12/15\n",
      "24/24 [==============================] - 133s 6s/step - loss: 2.0221 - accuracy: 0.8333 - precision_1: 0.8333 - recall_1: 0.8333 - auc_2: 0.8738 - val_loss: 0.5174 - val_accuracy: 0.9479 - val_precision_1: 0.9479 - val_recall_1: 0.9479 - val_auc_2: 0.9673\n",
      "Epoch 13/15\n",
      "24/24 [==============================] - 141s 6s/step - loss: 0.7484 - accuracy: 0.8932 - precision_1: 0.8932 - recall_1: 0.8932 - auc_2: 0.9265 - val_loss: 0.5160 - val_accuracy: 0.9479 - val_precision_1: 0.9479 - val_recall_1: 0.9479 - val_auc_2: 0.9771\n",
      "Epoch 14/15\n",
      "24/24 [==============================] - 145s 6s/step - loss: 0.6906 - accuracy: 0.9115 - precision_1: 0.9115 - recall_1: 0.9115 - auc_2: 0.9366 - val_loss: 0.7820 - val_accuracy: 0.9479 - val_precision_1: 0.9479 - val_recall_1: 0.9479 - val_auc_2: 0.9463\n",
      "Epoch 15/15\n",
      "24/24 [==============================] - 143s 6s/step - loss: 1.5807 - accuracy: 0.8464 - precision_1: 0.8464 - recall_1: 0.8464 - auc_2: 0.8861 - val_loss: 0.3258 - val_accuracy: 0.9583 - val_precision_1: 0.9583 - val_recall_1: 0.9583 - val_auc_2: 0.9774\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prepare_callbacks_config = config.get_prepare_callback_config()\n",
    "    prepare_callbacks = PrepareCallback(config=prepare_callbacks_config)\n",
    "    callback_list = prepare_callbacks.get_tb_ckpt_callbacks()\n",
    "\n",
    "    training_config = config.get_training_config()\n",
    "    training = Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.train_valid_generator()\n",
    "    training.train(\n",
    "        callback_list=callback_list\n",
    "    )\n",
    "    \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-02 22:27:12,306: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2023-12-02 22:27:12,312: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-12-02 22:27:12,315: INFO: common: created directory at: artifacts]\n",
      "[2023-12-02 22:27:12,316: INFO: common: created directory at: artifacts\\prepare_callbacks\\checkpoint_dir]\n",
      "[2023-12-02 22:27:12,319: INFO: common: created directory at: artifacts\\prepare_callbacks\\tensorboard_log_dir]\n",
      "[2023-12-02 22:27:12,334: INFO: common: created directory at: artifacts\\training]\n",
      "Found 78 images belonging to 2 classes.\n",
      "Found 312 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "19/19 [==============================] - ETA: 0s - loss: 11.0471 - accuracy: 0.5473"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\.conda\\envs\\chicken\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 118s 6s/step - loss: 11.0471 - accuracy: 0.5473 - val_loss: 13.5148 - val_accuracy: 0.6094\n",
      "Epoch 2/15\n",
      "19/19 [==============================] - 104s 5s/step - loss: 2.3805 - accuracy: 0.8041 - val_loss: 7.2440 - val_accuracy: 0.6094\n",
      "Epoch 3/15\n",
      "19/19 [==============================] - 119s 6s/step - loss: 1.8511 - accuracy: 0.8176 - val_loss: 0.7251 - val_accuracy: 0.8750\n",
      "Epoch 4/15\n",
      "19/19 [==============================] - 111s 6s/step - loss: 0.5646 - accuracy: 0.8919 - val_loss: 0.5403 - val_accuracy: 0.8906\n",
      "Epoch 5/15\n",
      "19/19 [==============================] - 109s 6s/step - loss: 1.5306 - accuracy: 0.8885 - val_loss: 1.3561 - val_accuracy: 0.7812\n",
      "Epoch 6/15\n",
      "19/19 [==============================] - 108s 6s/step - loss: 0.7230 - accuracy: 0.8953 - val_loss: 23.2085 - val_accuracy: 0.3906\n",
      "Epoch 7/15\n",
      "19/19 [==============================] - 94s 5s/step - loss: 1.3689 - accuracy: 0.8716 - val_loss: 0.5655 - val_accuracy: 0.9375\n",
      "Epoch 8/15\n",
      "19/19 [==============================] - 94s 5s/step - loss: 0.5847 - accuracy: 0.9257 - val_loss: 0.8115 - val_accuracy: 0.9219\n",
      "Epoch 9/15\n",
      "19/19 [==============================] - 109s 6s/step - loss: 0.1820 - accuracy: 0.9696 - val_loss: 0.5201 - val_accuracy: 0.9219\n",
      "Epoch 10/15\n",
      "19/19 [==============================] - 109s 6s/step - loss: 0.1650 - accuracy: 0.9696 - val_loss: 0.5027 - val_accuracy: 0.9375\n",
      "Epoch 11/15\n",
      "19/19 [==============================] - 101s 5s/step - loss: 0.2850 - accuracy: 0.9595 - val_loss: 0.4952 - val_accuracy: 0.9219\n",
      "Epoch 12/15\n",
      "19/19 [==============================] - 99s 5s/step - loss: 0.2022 - accuracy: 0.9561 - val_loss: 0.4817 - val_accuracy: 0.9531\n",
      "Epoch 13/15\n",
      "19/19 [==============================] - 99s 5s/step - loss: 0.1455 - accuracy: 0.9696 - val_loss: 0.4669 - val_accuracy: 0.9375\n",
      "Epoch 14/15\n",
      "19/19 [==============================] - 108s 6s/step - loss: 0.1166 - accuracy: 0.9696 - val_loss: 0.4732 - val_accuracy: 0.9531\n",
      "Epoch 15/15\n",
      "19/19 [==============================] - 136s 7s/step - loss: 0.0449 - accuracy: 0.9899 - val_loss: 0.5490 - val_accuracy: 0.9375\n"
     ]
    }
   ],
   "source": [
    "# Without Augmentation and additional layers\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prepare_callbacks_config = config.get_prepare_callback_config()\n",
    "    prepare_callbacks = PrepareCallback(config=prepare_callbacks_config)\n",
    "    callback_list = prepare_callbacks.get_tb_ckpt_callbacks()\n",
    "\n",
    "    training_config = config.get_training_config()\n",
    "    training = Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.train_valid_generator()\n",
    "    training.train(\n",
    "        callback_list=callback_list\n",
    "    )\n",
    "    \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-12-02 23:08:16,444: INFO: common: yaml file: config\\config.yaml loaded successfully]\n",
      "[2023-12-02 23:08:16,451: INFO: common: yaml file: params.yaml loaded successfully]\n",
      "[2023-12-02 23:08:16,454: INFO: common: created directory at: artifacts]\n",
      "[2023-12-02 23:08:16,457: INFO: common: created directory at: artifacts\\prepare_callbacks\\checkpoint_dir]\n",
      "[2023-12-02 23:08:16,460: INFO: common: created directory at: artifacts\\prepare_callbacks\\tensorboard_log_dir]\n",
      "[2023-12-02 23:08:16,465: INFO: common: created directory at: artifacts\\training]\n",
      "Found 78 images belonging to 2 classes.\n",
      "Found 312 images belonging to 2 classes.\n",
      "Epoch 1/15\n",
      "19/19 [==============================] - ETA: 0s - loss: 1.3416 - accuracy: 0.5236"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\DELL\\.conda\\envs\\chicken\\lib\\site-packages\\keras\\src\\engine\\training.py:3000: UserWarning: You are saving your model as an HDF5 file via `model.save()`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')`.\n",
      "  saving_api.save_model(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "19/19 [==============================] - 112s 6s/step - loss: 1.3416 - accuracy: 0.5236 - val_loss: 0.6957 - val_accuracy: 0.3906\n",
      "Epoch 2/15\n",
      "19/19 [==============================] - 107s 6s/step - loss: 0.5632 - accuracy: 0.6993 - val_loss: 1.0463 - val_accuracy: 0.3906\n",
      "Epoch 3/15\n",
      "19/19 [==============================] - 103s 5s/step - loss: 0.5275 - accuracy: 0.7534 - val_loss: 0.3471 - val_accuracy: 0.8906\n",
      "Epoch 4/15\n",
      "19/19 [==============================] - 104s 5s/step - loss: 0.6318 - accuracy: 0.6993 - val_loss: 1.3640 - val_accuracy: 0.3906\n",
      "Epoch 5/15\n",
      "19/19 [==============================] - 100s 5s/step - loss: 0.4908 - accuracy: 0.7635 - val_loss: 0.3172 - val_accuracy: 0.8750\n",
      "Epoch 6/15\n",
      "19/19 [==============================] - 99s 5s/step - loss: 0.4698 - accuracy: 0.7736 - val_loss: 0.5510 - val_accuracy: 0.7188\n",
      "Epoch 7/15\n",
      "19/19 [==============================] - 100s 5s/step - loss: 0.3655 - accuracy: 0.8378 - val_loss: 0.7983 - val_accuracy: 0.6406\n",
      "Epoch 8/15\n",
      "19/19 [==============================] - 100s 5s/step - loss: 0.2728 - accuracy: 0.8953 - val_loss: 0.2656 - val_accuracy: 0.9219\n",
      "Epoch 9/15\n",
      "19/19 [==============================] - 99s 5s/step - loss: 0.2246 - accuracy: 0.9291 - val_loss: 0.3479 - val_accuracy: 0.8594\n",
      "Epoch 10/15\n",
      "19/19 [==============================] - 99s 5s/step - loss: 0.4430 - accuracy: 0.8446 - val_loss: 0.2946 - val_accuracy: 0.8906\n",
      "Epoch 11/15\n",
      "19/19 [==============================] - 101s 5s/step - loss: 0.2232 - accuracy: 0.9079 - val_loss: 0.3049 - val_accuracy: 0.8750\n",
      "Epoch 12/15\n",
      "19/19 [==============================] - 100s 5s/step - loss: 0.2195 - accuracy: 0.9155 - val_loss: 0.2590 - val_accuracy: 0.9219\n",
      "Epoch 13/15\n",
      "19/19 [==============================] - 100s 5s/step - loss: 0.2632 - accuracy: 0.8919 - val_loss: 0.2296 - val_accuracy: 0.9219\n",
      "Epoch 14/15\n",
      "19/19 [==============================] - 99s 5s/step - loss: 0.2679 - accuracy: 0.8851 - val_loss: 0.2761 - val_accuracy: 0.9062\n",
      "Epoch 15/15\n",
      "19/19 [==============================] - 98s 5s/step - loss: 0.2217 - accuracy: 0.9189 - val_loss: 0.5079 - val_accuracy: 0.7656\n"
     ]
    }
   ],
   "source": [
    "# With additional dense layers\n",
    "try:\n",
    "    config = ConfigurationManager()\n",
    "    prepare_callbacks_config = config.get_prepare_callback_config()\n",
    "    prepare_callbacks = PrepareCallback(config=prepare_callbacks_config)\n",
    "    callback_list = prepare_callbacks.get_tb_ckpt_callbacks()\n",
    "\n",
    "    training_config = config.get_training_config()\n",
    "    training = Training(config=training_config)\n",
    "    training.get_base_model()\n",
    "    training.train_valid_generator()\n",
    "    training.train(\n",
    "        callback_list=callback_list\n",
    "    )\n",
    "    \n",
    "except Exception as e:\n",
    "    raise e"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "chicken",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
